{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f37dc61a-14bb-443c-8239-e435a0dcc07b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 153)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<string>:153\u001b[1;36m\u001b[0m\n\u001b[1;33m    if criterion == \"entropy\":\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from pyvi import ViTokenizer\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "INPUT = 'data/news_vnexpress'\n",
    "os.makedirs(\"images\",exist_ok=True)  # thư mục lưu các hình ảnh kết quả trong quá trình huấn luyện và đánh giá\n",
    "\n",
    "# statistics\n",
    "print('Các nhãn và số văn bản tương ứng trong dữ liệu')\n",
    "print('----------------------------------------------')\n",
    "tongbv = 0\n",
    "for label in os.listdir(INPUT):\n",
    "    print(f'{label}: {len(os.listdir(os.path.join(INPUT, label)))}')  #duyet qua thu muc INPUT va in ten cac thu muc con va sl tep\n",
    "    n += len(os.listdir(os.path.join(INPUT, label)))\n",
    "\n",
    "print('-------------------------')\n",
    "print(f\"Tổng số văn bản: {tongbv}\")\n",
    "\n",
    "# load data\n",
    "data_train = load_files(container_path=INPUT, encoding=\"utf-8\")\n",
    "\n",
    "print('mapping:')\n",
    "for i in range(len(data_train.target_names)):\n",
    "    print(f'{data_train.target_names[i]} - {i}')\n",
    "\n",
    "print('--------------------------')\n",
    "print(data_train.filenames[0:1])\n",
    "# print(data_train.data[0:1])\n",
    "print(data_train.target[0:1])\n",
    "print(data_train.data[0:1])\n",
    "\n",
    "print(\"\\nTổng số  văn bản: {}\" .format( len(data_train.filenames)))\n",
    "\n",
    "# load dữ liệu các stopwords \n",
    "with open(\"data/vietnamese-stopwords.txt\", encoding=\"utf-8\") as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip().replace(\" \", \"_\") for x in stopwords]  #strip() sẽ loại bỏ khoảng trắng 2 phía và replace để thay thế khoảng trắng bằng dấu _\n",
    "print(f\"Số lượng stopwords: {len(stopwords)}\")\n",
    "print(stopwords[:10])\n",
    "\n",
    "# Chuyển hoá dữ liệu text về dạng vector TF \n",
    "#     - loại bỏ từ dừng\n",
    "#     - sinh từ điển\n",
    "module_count_vector = CountVectorizer(stop_words=stopwords)  #chỉnh định từ cần loại bỏ là cac stopword từ file vua doc\n",
    "model_rf_preprocess = Pipeline([('vect', module_count_vector),\n",
    "                    ('tf', TfidfTransformer()),\n",
    "                    ])\n",
    "# Hàm thực hiện chuyển đổi dữ liệu text thành dữ liệu số dạng ma trận \n",
    "# Input: Dữ liệu 2 chiều dạng numpy.array, mảng nhãn id dạng numpy.array \n",
    "data_preprocessed = model_rf_preprocess.fit_transform(data_train.data, data_train.target)\n",
    "\n",
    "print(f\"\\nSố lượng từ trong từ điển: {len(module_count_vector.vocabulary_)}\")\n",
    "print(f\"Kích thước dữ liệu sau khi xử lý: {data_preprocessed.shape}\")\n",
    "print(f\"Kích thước nhãn tương ứng: {data_train.target.shape}\")\n",
    "\n",
    "#chia \n",
    "p = 0.2\n",
    "pivot = int(data_preprocessed.shape[0] * (1-0.2))\n",
    "X_train, X_test = data_preprocessed[0:pivot], data_preprocessed[pivot:]\n",
    "print('X')\n",
    "Y_train, Y_test = data_train.target[0:pivot], data_train.target[pivot:]\n",
    "\n",
    "def cross_validation(estimator):\n",
    "    _, train_scores, test_scores = learning_curve(estimator, X_train, Y_train, cv=10, n_jobs=-1, train_sizes=[1.0, ], scoring=\"accuracy\")\n",
    "    test_scores = test_scores[0]\n",
    "    mean, std = test_scores.mean(), test_scores.std()\n",
    "    return mean, std\n",
    "\n",
    "def plot(title, xlabel, X, Y, error, ylabel = \"Accuracy\"):\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.title(title)\n",
    "    plt.grid()\n",
    "    plt.ylabel(ylabel)\n",
    "    \n",
    "    plt.errorbar(X, Y, error, linestyle='None', marker='o')\n",
    "\n",
    "# Đánh giá hiệu quả của các kernel trong SVM\n",
    "title = \"thay đổi kernel, C = 1\"\n",
    "xlabel = \"kernel\"\n",
    "X = []\n",
    "Y = []\n",
    "error = []\n",
    "\n",
    "for kernel in tqdm(['linear', 'poly', 'rbf', 'sigmoid']):\n",
    "    # Với mỗi kernel được chọn, \n",
    "    # thực hiện xây dựng mô hình, huấn luyện và đánh giá theo cross-validation\n",
    "    text_clf = svm.SVC(kernel=kernel, C=1.0)\n",
    "    mean, std = cross_validation(text_clf)\n",
    "    X.append(kernel)\n",
    "    Y.append(mean)\n",
    "    error.append(std)\n",
    "\n",
    "# lưu kết quả ra file ảnh \n",
    "plot(title, xlabel, X, Y, error)\n",
    "plt.savefig('images/svm_change_kernel.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "title = \"thay đổi C, kernel = linear\"\n",
    "xlabel = \"C\"\n",
    "X = []\n",
    "Y = []\n",
    "error = []\n",
    "\n",
    "for C in tqdm([.1, 1.0, 2.0, 5.0, 10.0]):\n",
    "    # Với từng giá trị C nhận được, \n",
    "    # thực hiện xây dựng mô hình, huấn luyện và đánh giá theo cross-validation\n",
    "    text_clf = svm.SVC(kernel='linear', C=C)\n",
    "    mean, std = cross_validation(text_clf)\n",
    "    X.append(str(C))\n",
    "    Y.append(mean)\n",
    "    error.append(std)\n",
    "\n",
    "# lưu kết quả ra file ảnh\n",
    "plot(title, xlabel, X, Y, error)\n",
    "plt.savefig('images/svm_change_C.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "title = \"thay đổi criterion, n_estimators = 50\"\n",
    "xlabel = \"criterion\"\n",
    "X = []\n",
    "Y = []\n",
    "error = []\n",
    "\n",
    "for criterion in tqdm([\"gini\", \"entropy\"]):\n",
    "    # Với mỗi criterion nhận được,\n",
    "    # thực hiện xây dựng mô hình, huấn luyện và đánh giá theo cross-validation\n",
    "    text_clf = RandomForestClassifier(criterion=criterion, n_estimators=50)\n",
    "    mean, std = cross_validation(text_clf)\n",
    "    X.append(str(criterion))\n",
    "    Y.append(mean)\n",
    "    error.append(std)\n",
    "\n",
    "\n",
    " # In ra giá trị Gini impurity\n",
    "    if criterion == \"gini\":\n",
    "        print(\"Gini impurity:\", mean)\n",
    "    else:\n",
    "       print(\"entropy:\", mean)\n",
    "        \n",
    "     \n",
    "\n",
    "# lưu kết quả ra file ảnh\n",
    "plot(title, xlabel, X, Y, error)\n",
    "plt.savefig('images/RF_change_criterion.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "title = \"thay đổi n_estimators, criterion = gini\"\n",
    "xlabel = \"n_estimators\"\n",
    "X = []\n",
    "Y = []\n",
    "error = []\n",
    "\n",
    "for n_estimators in tqdm([10, 50, 100, 300]):\n",
    "    # Với từng giá trị n_estimators nhận được,\n",
    "    # thực hiện xây dựng mô hình, huấn luyện và đánh giá theo cross-validation\n",
    "    text_clf = RandomForestClassifier(criterion='gini', n_estimators=n_estimators)\n",
    "    mean, std = cross_validation(text_clf)\n",
    "    X.append(str(n_estimators))\n",
    "    Y.append(mean)\n",
    "    error.append(std)\n",
    "\n",
    "# lưu kết quả ra file ảnh\n",
    "plot(title, xlabel, X, Y, error)\n",
    "plt.savefig('images/RF_change_N.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "svm_ = svm.SVC(kernel='linear', C=1.0)\n",
    "rf = RandomForestClassifier(criterion='gini', n_estimators=100)\n",
    "\n",
    "# Huấn luyện các mô hình trên tập dữ liệu train đầy đủ\n",
    "svm_.fit(X_train, Y_train)\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "# Kết quả dự đoán trên tập test\n",
    "print(f'SVM: {accuracy_score(Y_test, svm_.predict(X_test))}')\n",
    "print(f'RF: {accuracy_score(Y_test, rf.predict(X_test))}')\n",
    "\n",
    "# Dự đoán nhãn từ mô hình\n",
    "y_pred_svm = svm_.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Tạo ma trận nhầm lẫn\n",
    "cm_svm = confusion_matrix(Y_test, y_pred_svm)\n",
    "cm_rf = confusion_matrix(Y_test, y_pred_rf)\n",
    "\n",
    "# Hiển thị ma trận nhầm lẫn\n",
    "disp_svm = ConfusionMatrixDisplay(confusion_matrix=cm_svm)\n",
    "disp_svm.plot()\n",
    "plt.title(\"Confusion Matrix - SVM\")\n",
    "plt.show()\n",
    "\n",
    "disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf)\n",
    "disp_rf.plot()\n",
    "plt.title(\"Confusion Matrix - Random Forest\")\n",
    "plt.show()\n",
    "\n",
    "##thanh dài -0- là đổ lệch chuẩn, càng nhỏ thì càng ổn định\n",
    "# Cross Validation đánh giá hiệu suất\n",
    "#Kernel: Là một hàm được sử dụng để chuyển đổi dữ liệu đầu vào sang một không gian chiều cao hơn (có thể là vô hạn chiều) để dễ dàng phân loại. Các kernel phổ biến trong SVM bao gồm:\n",
    "\n",
    "#Linear (tuyến tính): Dữ liệu được chuyển đổi một cách tuyến tính.\n",
    "#Polynomial (đa thức): Dữ liệu được chuyển đổi bằng một đa thức.\n",
    "#RBF (Radial Basis Function): Dữ liệu được chuyển đổi bằng một hàm RBF.\n",
    "#Sigmoid (sigmoid): Dữ liệu được chuyển đổi bằng một hàm sigmoid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6accde-5695-4c2e-8c7b-83eac5d68b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20387d5f-5263-4a48-b120-d866c9f3ebfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41141a00-cd69-4b3a-8e74-39bfe72f2144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37183b0a-f3ec-4504-be3e-4ccc8447c229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece4cbbd-e184-47ed-97eb-8b12b2d41e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
