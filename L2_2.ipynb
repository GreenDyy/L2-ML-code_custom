{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e2c7fa-d8e4-4b3b-9a54-5103773386cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các nhãn và số văn bản tương ứng trong dữ liệu\n",
      "----------------------------------------------\n",
      "doi-song: 120\n",
      "du-lich: 54\n",
      "giai-tri: 201\n",
      "giao-duc: 105\n",
      "khoa-hoc: 144\n",
      "kinh-doanh: 262\n",
      "phap-luat: 59\n",
      "suc-khoe: 162\n",
      "the-thao: 173\n",
      "thoi-su: 59\n",
      "-------------------------\n",
      "Tổng số văn bản: 1339\n",
      "\n",
      "-----------Load Data-----------\n",
      "mapping:\n",
      "doi-song - 0\n",
      "du-lich - 1\n",
      "giai-tri - 2\n",
      "giao-duc - 3\n",
      "khoa-hoc - 4\n",
      "kinh-doanh - 5\n",
      "phap-luat - 6\n",
      "suc-khoe - 7\n",
      "the-thao - 8\n",
      "thoi-su - 9\n",
      "Bài viết đầu tiên\n",
      "['data/news_vnexpress\\\\khoa-hoc\\\\00133.txt']\n",
      "[4]\n",
      "['Mời độc giả đặt câu hỏi tại đây\\n']\n",
      "\n",
      "Tổng số  văn bản: 1339\n",
      "\n",
      "-------------Load Stopwords-------------\n",
      "Số lượng stopwords trong file vietnamese-stopwords.txt: 2063\n",
      "10 từ đầu tiên:\n",
      "['a_lô', 'a_ha', 'ai', 'ai_ai', 'ai_nấy', 'ai_đó', 'alô', 'amen', 'anh', 'anh_ấy']\n",
      "Pipeline(steps=[('vect',\n",
      "                 CountVectorizer(stop_words=['a_lô', 'a_ha', 'ai', 'ai_ai',\n",
      "                                             'ai_nấy', 'ai_đó', 'alô', 'amen',\n",
      "                                             'anh', 'anh_ấy', 'ba', 'ba_ba',\n",
      "                                             'ba_bản', 'ba_cùng', 'ba_họ',\n",
      "                                             'ba_ngày', 'ba_ngôi', 'ba_tăng',\n",
      "                                             'bao_giờ', 'bao_lâu', 'bao_nhiêu',\n",
      "                                             'bao_nả', 'bay_biến', 'biết',\n",
      "                                             'biết_bao', 'biết_bao_nhiêu',\n",
      "                                             'biết_chắc', 'biết_chừng_nào',\n",
      "                                             'biết_mình', 'biết_mấy', ...])),\n",
      "                ('tfidf', TfidfTransformer())])\n",
      "\n",
      "Số lượng từ trong từ điển: 12796\n",
      "Kích thước dữ liệu sau khi xử lý: (1339, 12796)\n",
      "Kích thước nhãn tương ứng: (1339,)\n",
      "Vectơ TF-IDF của văn bản thứ 100 dưới dạng mảng numpy.\n",
      "Vectơ TF-IDF của văn bản thứ 100 dưới dạng mảng numpy.\n",
      "  (0, 12794)\t0.14048828324700804\n",
      "  (0, 12724)\t0.051226678060487627\n",
      "  (0, 12714)\t0.034379239518190156\n",
      "  (0, 12705)\t0.024927343279465615\n",
      "  (0, 12697)\t0.03935911209707954\n",
      "  (0, 12692)\t0.013885134230282647\n",
      "  (0, 12691)\t0.02076954755505395\n",
      "  (0, 12672)\t0.03173992101554847\n",
      "  (0, 12646)\t0.04268947993761032\n",
      "  (0, 12643)\t0.030193779677554416\n",
      "  (0, 12629)\t0.024173036345759045\n",
      "  (0, 12626)\t0.01928809379275951\n",
      "  (0, 12624)\t0.3318224864003995\n",
      "  (0, 12617)\t0.08000423234784886\n",
      "  (0, 12591)\t0.07519534686809994\n",
      "  (0, 12584)\t0.03876774373554222\n",
      "  (0, 12566)\t0.033240367004725005\n",
      "  (0, 12558)\t0.03206234356763185\n",
      "  (0, 12547)\t0.04575286598942787\n",
      "  (0, 12535)\t0.05488370325838488\n",
      "  (0, 12521)\t0.09355442947181113\n",
      "  (0, 12517)\t0.03883219864696093\n",
      "  (0, 12509)\t0.017786174579851665\n",
      "  (0, 12454)\t0.07589970050190288\n",
      "  (0, 12272)\t0.02125953768208212\n",
      "  :\t:\n",
      "  (0, 2170)\t0.029508397725910254\n",
      "  (0, 2159)\t0.016084504788746505\n",
      "  (0, 2140)\t0.015661963686282587\n",
      "  (0, 2135)\t0.04322051581452054\n",
      "  (0, 2111)\t0.025775634654335113\n",
      "  (0, 2101)\t0.026936724711167648\n",
      "  (0, 2076)\t0.014547704347804934\n",
      "  (0, 1866)\t0.05117031195708947\n",
      "  (0, 1783)\t0.0473450956087146\n",
      "  (0, 1631)\t0.023493949966261328\n",
      "  (0, 1590)\t0.03492662390306206\n",
      "  (0, 1271)\t0.01600570513441007\n",
      "  (0, 1219)\t0.05117031195708947\n",
      "  (0, 1209)\t0.10234062391417895\n",
      "  (0, 1194)\t0.05117031195708947\n",
      "  (0, 909)\t0.03318224864003995\n",
      "  (0, 662)\t0.022769929356223212\n",
      "  (0, 418)\t0.04891806652384772\n",
      "  (0, 397)\t0.03423295419235291\n",
      "  (0, 392)\t0.024783841259467598\n",
      "  (0, 269)\t0.033240367004725005\n",
      "  (0, 188)\t0.04722498744523732\n",
      "  (0, 156)\t0.023262873797037946\n",
      "  (0, 100)\t0.02076954755505395\n",
      "  (0, 81)\t0.015211595534715629\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pyvi import ViTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "INPUT = 'data/news_vnexpress'\n",
    "os.makedirs(\"images\",exist_ok=True)  # thư mục lưu các các hình ảnh kết quả trong quá trình huấn luyện và đánh giá\n",
    "\n",
    "# số liệu thống kê\n",
    "print('Các nhãn và số văn bản tương ứng trong dữ liệu')\n",
    "print('----------------------------------------------')\n",
    "n = 0\n",
    "for label in os.listdir(INPUT):\n",
    "    print(f'{label}: {len(os.listdir(os.path.join(INPUT, label)))}')\n",
    "    n += len(os.listdir(os.path.join(INPUT, label)))\n",
    "\n",
    "print('-------------------------')\n",
    "print(f\"Tổng số văn bản: {n}\")\n",
    "\n",
    "# load data\n",
    "print('\\n-----------Load Data-----------')\n",
    "data_train = load_files(container_path=INPUT, encoding=\"utf-8\")\n",
    "print('mapping:')\n",
    "for i in range(len(data_train.target_names)):\n",
    "    print(f'{data_train.target_names[i]} - {i}')\n",
    "\n",
    "print('Bài viết đầu tiên')\n",
    "print(data_train.filenames[0:1]) #in đường dẫn\n",
    "# print(data_train.data[0:1])\n",
    "print(data_train.target[0:1]) #nhãn\n",
    "print(data_train.data[0:1]) #nội dung\n",
    "\n",
    "print(\"\\nTổng số  văn bản:\", len(data_train.filenames))\n",
    "\n",
    "\n",
    "# load dữ liệu các stopwords \n",
    "print(\"\\n-------------Load Stopwords-------------\")\n",
    "with open(\"data/vietnamese-stopwords.txt\", encoding=\"utf-8\") as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip().replace(\" \", \"_\") for x in stopwords] \n",
    "print(f\"Số lượng stopwords trong file vietnamese-stopwords.txt: {len(stopwords)}\")\n",
    "print(\"10 từ đầu tiên:\")\n",
    "print(stopwords[:10])\n",
    "\n",
    "# Chuyển hoá dữ liệu text về dạng vector TF \n",
    "#     - loại bỏ từ dừng\n",
    "#     - sinh từ điển\n",
    "module_count_vector = CountVectorizer(stop_words=stopwords) #tại đây sinh từ điển và loại bỏ từ dùng\n",
    "model_rf_preprocess = Pipeline([('vect', module_count_vector), #tạo một Pipeline trong Scikit-learn để kết hợp hai bước tiền xử lý dữ liệu là cái sinh từ điển và kỹ thuật TF-IDF\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ])\n",
    "\n",
    "print(model_rf_preprocess)\n",
    "# Hàm thực hiện chuyển đổi dữ liệu text thành dữ liệu số dạng ma trận \n",
    "# Input: Dữ liệu 2 chiều dạng numpy.array, mảng nhãn id dạng numpy.array \n",
    "data_preprocessed = model_rf_preprocess.fit_transform(data_train.data, data_train.target)\n",
    "\n",
    "print(f\"\\nSố lượng từ trong từ điển: {len(module_count_vector.vocabulary_)}\") #là những từ chỉ xuất hiện 1 lần, xuật hiện nữa thì ko +\n",
    "print(f\"Kích thước dữ liệu sau khi xử lý: {data_preprocessed.shape}\")\n",
    "print(f\"Kích thước nhãn tương ứng: {data_train.target.shape}\")\n",
    "\n",
    "X = data_preprocessed\n",
    "Y = data_train.target\n",
    "\n",
    "X.shape, Y.shape\n",
    "print(\"Vectơ TF-IDF của văn bản thứ 100 dưới dạng mảng numpy.\")\n",
    "\n",
    "\n",
    "sum(sum(X[100].toarray() != 0)) #tính tổng số lần xuất hiện của các từ khác không trong văn bản thứ 100\n",
    "\n",
    "print(\"Vectơ TF-IDF của văn bản thứ 100 dưới dạng mảng numpy.\") \n",
    "#dòng đầu tiên (0, 12794) có nghĩa là từ có chỉ số 12794 trong từ điển xuất hiện trong văn bản này, \n",
    "#và giá trị TF-IDF tương ứng của từ đó là 0.14048828324700804.\n",
    "print(X[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf336b7d-887a-4303-b908-ef67a9eb36d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
