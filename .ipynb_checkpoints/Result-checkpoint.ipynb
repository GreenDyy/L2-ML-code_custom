{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e98608-64c4-4ad4-9da3-eb219201bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from pyvi import ViTokenizer\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "INPUT = 'data/news_vnexpress'\n",
    "os.makedirs(\"images\",exist_ok=True)  # thư mục lưu các hình ảnh kết quả trong quá trình huấn luyện và đánh giá\n",
    "\n",
    "# statistics\n",
    "print('Các nhãn và số văn bản tương ứng trong dữ liệu')\n",
    "print('----------------------------------------------')\n",
    "n = 0\n",
    "for label in os.listdir(INPUT):\n",
    "    print(f'{label}: {len(os.listdir(os.path.join(INPUT, label)))}')  #duyet qua thu muc INPUT va in ten cac thu muc con va sl tep\n",
    "    n += len(os.listdir(os.path.join(INPUT, label)))\n",
    "\n",
    "print('-------------------------')\n",
    "print(f\"Tổng số văn bản: {n}\")\n",
    "\n",
    "# load data\n",
    "data_train = load_files(container_path=INPUT, encoding=\"utf-8\")\n",
    "\n",
    "print('mapping:')\n",
    "for i in range(len(data_train.target_names)):\n",
    "    print(f'{data_train.target_names[i]} - {i}')\n",
    "\n",
    "print('-----------Dữ liệu của bài viết đầu tiên-----------')\n",
    "print('tên file:', data_train.filenames[0:1])\n",
    "print('data_train:', data_train.data[0:1])\n",
    "print('target:', data_train.target[0:1])\n",
    "\n",
    "print(\"\\nTổng số  văn bản: {}\" .format( len(data_train.filenames)))\n",
    "\n",
    "# load dữ liệu các stopwords \n",
    "with open(\"data/vietnamese-stopwords.txt\", encoding=\"utf-8\") as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip().replace(\" \", \"_\") for x in stopwords]    #strip() sẽ loại bỏ khoảng trắng 2 phía và replace để thay thế khoảng trắng bằng dấu _\n",
    "print(f\"Số lượng stopwords: {len(stopwords)}\")\n",
    "print(stopwords[:10])\n",
    "\n",
    "# Chuyển hoá dữ liệu text về dạng vector TF print(module_count_vector)\n",
    "#     - loại bỏ từ dừng\n",
    "#     - sinh từ điển\n",
    "module_count_vector = CountVectorizer(stop_words=stopwords) #chỉnh định từ cần loại bỏ là cac stopword từ file vua doc\n",
    "model_rf_preprocess = Pipeline([('vect', module_count_vector),('tf', TfidfTransformer()),]) #truyền vào các bước thực hiện tuần tự\n",
    "\n",
    "# Hàm thực hiện chuyển đổi dữ liệu text thành dữ liệu số dạng ma trận \n",
    "# Input: Dữ liệu 2 chiều dạng numpy.array, mảng nhãn id dạng numpy.array \n",
    "data_preprocessed = model_rf_preprocess.fit_transform(data_train.data, data_train.target)\n",
    "# In ra một mẫu dữ liệu văn bản trước khi xử lý\n",
    "print(\"Dữ liệu văn bản trước khi xử lý:\")\n",
    "print(data_train.data[0])\n",
    "\n",
    "# In ra một mẫu dữ liệu văn bản sau khi xử lý\n",
    "print(\"\\nDữ liệu văn bản sau khi xử lý:\")\n",
    "print(data_preprocessed[0])\n",
    "\n",
    "#0 là chỉ số của mẫu văn bản.\n",
    "#12711 là chỉ số của từ trong từ điển. Mỗi từ trong từ điển sẽ được gán một chỉ số.\n",
    "#0.47047455226652657 là giá trị TF-IDF của từ tương ứng (có chỉ số là 12711) trong mẫu văn bản đó.\n",
    "#nó có nhiều từ mà chỉ còn vài dòng là do mốt số từ đã bị loại do có chỉ số TFIDF sap si bang 0\n",
    "\n",
    "print(f\"\\nSố lượng từ trong từ điển: {len(module_count_vector.vocabulary_)}\")\n",
    "print(f\"Kích thước dữ liệu sau khi xử lý: {data_preprocessed.shape}\")\n",
    "print(f\"Kích thước nhãn tương ứng: {data_train.target.shape}\")\n",
    "\n",
    "#chia \n",
    "pivot = int(data_preprocessed.shape[0] * 0.8) # shape[0] la dong, 1 la cot, ma tran thua thì nó bo may cai cot co gia tri la 0 roi\n",
    "print('pivot:',pivot)\n",
    "X_train, X_test = data_preprocessed[0:pivot], data_preprocessed[pivot:]\n",
    "print('X')\n",
    "Y_train, Y_test = data_train.target[0:pivot], data_train.target[pivot:]\n",
    "\n",
    "#Lựa chọn (tối ưu) tham số\n",
    "def cross_validation(estimator): #tham số estimator là mô hình sẽ đưa vào\n",
    "    _, train_scores, test_scores = learning_curve(estimator, X_train, Y_train, cv=10, n_jobs=-1, train_sizes=[1.0, ], scoring=\"accuracy\")\n",
    "    test_scores = test_scores[0]\n",
    "    mean, std = test_scores.mean(), test_scores.std()\n",
    "    return mean, std\n",
    "\n",
    "def plot(title, xlabel, X, Y, error, ylabel = \"Accuracy\"):\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.title(title)\n",
    "    plt.grid()\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.errorbar(X, Y, error, linestyle='None', marker='o')\n",
    "\n",
    "# Đánh giá hiệu quả của các kernel trong SVM\n",
    "title = \"thay đổi kernel, C = 1\"\n",
    "xlabel = \"kernel\"\n",
    "X = []\n",
    "Y = []\n",
    "error = []\n",
    "\n",
    "for kernel in tqdm(['linear', 'poly', 'rbf', 'sigmoid']):\n",
    "    # Với mỗi kernel được chọn, \n",
    "    # thực hiện xây dựng mô hình, huấn luyện và đánh giá theo cross-validation\n",
    "    text_clf = svm.SVC(kernel=kernel, C=1.0)\n",
    "    mean, std = cross_validation(text_clf)\n",
    "    X.append(kernel)\n",
    "    Y.append(mean)\n",
    "    error.append(std)\n",
    "\n",
    "# lưu kết quả ra file ảnh \n",
    "plot(title, xlabel, X, Y, error)\n",
    "plt.savefig('images/svm_change_kernel.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#Đánh giá ảnh hưởng của tham số C trong SVM\n",
    "title = \"thay đổi C, kernel = linear\"\n",
    "xlabel = \"C\"\n",
    "X = []\n",
    "Y = []\n",
    "error = []\n",
    "\n",
    "for C in tqdm([.1, 1.0, 2.0, 5.0, 10.0]):\n",
    "    # Với từng giá trị C nhận được, \n",
    "    # thực hiện xây dựng mô hình, huấn luyện và đánh giá theo cross-validation\n",
    "    text_clf = svm.SVC(kernel='linear', C=C)\n",
    "    mean, std = cross_validation(text_clf)\n",
    "    X.append(str(C))\n",
    "    Y.append(mean)\n",
    "    error.append(std)\n",
    "\n",
    "# lưu kết quả ra file ảnh\n",
    "plot(title, xlabel, X, Y, error)\n",
    "plt.savefig('images/svm_change_C.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#Đánh giá ảnh hưởng của độ đo trong Random Forest\n",
    "title = \"thay đổi criterion, n_estimators = 50\"\n",
    "xlabel = \"criterion\"\n",
    "X = []\n",
    "Y = []\n",
    "error = []\n",
    "\n",
    "for criterion in tqdm([\"gini\", \"entropy\"]):\n",
    "    # Với mỗi criterion nhận được,\n",
    "    # thực hiện xây dựng mô hình, huấn luyện và đánh giá theo cross-validation\n",
    "    text_clf = RandomForestClassifier(criterion=criterion, n_estimators=50)\n",
    "    mean, std = cross_validation(text_clf)\n",
    "    X.append(str(criterion))\n",
    "    Y.append(mean)\n",
    "    error.append(std)\n",
    "\n",
    "# lưu kết quả ra file ảnh\n",
    "plot(title, xlabel, X, Y, error)\n",
    "plt.savefig('images/RF_change_criterion.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#Đánh giá ảnh hưởng của số cây trong Random Forest\n",
    "title = \"thay đổi n_estimators, criterion = gini\"\n",
    "xlabel = \"n_estimators\"\n",
    "X = []\n",
    "Y = []\n",
    "error = []\n",
    "\n",
    "for n_estimators in tqdm([10, 50, 100, 300]):\n",
    "    # Với từng giá trị n_estimators nhận được,\n",
    "    # thực hiện xây dựng mô hình, huấn luyện và đánh giá theo cross-validation\n",
    "    text_clf = RandomForestClassifier(criterion='gini', n_estimators=n_estimators)\n",
    "    mean, std = cross_validation(text_clf)\n",
    "    X.append(str(n_estimators))\n",
    "    Y.append(mean)\n",
    "    error.append(std)\n",
    "\n",
    "# lưu kết quả ra file ảnh\n",
    "plot(title, xlabel, X, Y, error)\n",
    "plt.savefig('images/RF_change_N.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "svm_ = svm.SVC(kernel='linear', C=1.0)\n",
    "rf = RandomForestClassifier(criterion='gini', n_estimators=100)\n",
    "\n",
    "# Huấn luyện các mô hình trên tập dữ liệu train đầy đủ\n",
    "svm_.fit(X_train, Y_train)\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "# Kết quả dự đoán trên tập test\n",
    "print(f'SVM: {accuracy_score(Y_test, svm_.predict(X_test))}')\n",
    "print(f'RF: {accuracy_score(Y_test, rf.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c7d355-308b-4511-8a4e-7d016e910869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
